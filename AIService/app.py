# app.py

import os
import json
import random
from flask import Flask, request, jsonify
from dotenv import load_dotenv

# --- CLIENT C·ª¶A C√ÅC NH√Ä CUNG C·∫§P AI ---
import google.generativeai as genai
from perplexity import Perplexity # Nh·∫≠p th∆∞ vi·ªán Perplexity

# --- KH·ªûI T·∫†O V√Ä C·∫§U H√åNH ---

# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env (n·∫øu c√≥)
load_dotenv()

# T·∫°o ·ª©ng d·ª•ng Flask
app = Flask(__name__)

# --- C·∫§U H√åNH CHO GOOGLE GEMINI ---
try:
    gemini_api_key = os.environ.get("GOOGLE_API_KEY")
    if not gemini_api_key:
        raise ValueError("L·ªói: Bi·∫øn m√¥i tr∆∞·ªùng GOOGLE_API_KEY ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p.")
    genai.configure(api_key=gemini_api_key)
    
    # C·∫•u h√¨nh m√¥ h√¨nh Gemini 1.5 Flash
    gemini_generation_config = {
      "temperature": 1,
      "top_p": 0.95,
      "top_k": 64,
      "max_output_tokens": 8192,
      "response_mime_type": "application/json",
    }
    gemini_model = genai.GenerativeModel(
      model_name="gemini-1.5-flash-latest",
      generation_config=gemini_generation_config
    )
    print("‚úÖ C·∫•u h√¨nh Google Gemini th√†nh c√¥ng.")
except Exception as e:
    print(f"üö® L·ªói khi c·∫•u h√¨nh Google Gemini: {e}")
    gemini_model = None

# --- C·∫§U H√åNH CHO PERPLEXITY ---
try:
    # Client Perplexity s·∫Ω t·ª± ƒë·ªông ƒë·ªçc key t·ª´ bi·∫øn m√¥i tr∆∞·ªùng PERPLEXITY_API_KEY
    perplexity_client = Perplexity()
    print("‚úÖ C·∫•u h√¨nh Perplexity th√†nh c√¥ng.")
except Exception as e:
    print(f"üö® L·ªói khi c·∫•u h√¨nh Perplexity: {e}")
    perplexity_client = None

# --- C√ÅC ROUTE C·ª¶A API ---

@app.route('/')
def index():
    """H√†m ch√†o m·ª´ng khi truy c·∫≠p v√†o trang ch·ªß."""
    return "<h1>Ch√†o m·ª´ng ƒë·∫øn v·ªõi API Ph·ªèng v·∫•n AI (Gemini + Perplexity)!</h1>"

@app.route('/api/generate_question', methods=['POST'])
def generate_question_api():
    """
    API endpoint ƒë·ªÉ t·∫°o c√¢u h·ªèi ph·ªèng v·∫•n, s·ª≠ d·ª•ng Google Gemini 1.5 Flash.
    """
    if not gemini_model:
        return jsonify({"error": "D·ªãch v·ª• Gemini ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh ƒë√∫ng."}), 503

    try:
        data = request.get_json()
    except Exception:
        return jsonify({"error": "Request body kh√¥ng ph·∫£i l√† JSON h·ª£p l·ªá."}), 400

    job_position = data.get("jobPosition", "developer")
    topic = data.get("topic", "Software Engineering")
    industry = data.get("industry", "IT")

    print(f"üì© [Gemini] Nh·∫≠n y√™u c·∫ßu t·∫°o c√¢u h·ªèi cho '{job_position}'")

    prompt = f"""
    B·∫°n l√† m·ªôt chuy√™n gia tuy·ªÉn d·ª•ng k·ªπ thu·∫≠t. H√£y t·∫°o ra M·ªòT c√¢u h·ªèi ph·ªèng v·∫•n DUY NH·∫§T.
    Th√¥ng tin ·ª©ng vi√™n:
    - V·ªã tr√≠: {job_position}
    - Ch·ªß ƒë·ªÅ chuy√™n m√¥n: {topic}
    - Lƒ©nh v·ª±c c√¥ng ty: {industry}
    Y√™u c·∫ßu quan tr·ªçng: Ch·ªâ tr·∫£ v·ªÅ m·ªôt ƒë·ªëi t∆∞·ª£ng JSON duy nh·∫•t c√≥ c·∫•u tr√∫c sau:
    {{
      "questionText": "N·ªôi dung c√¢u h·ªèi ·ªü ƒë√¢y",
      "difficultyLevel": <m·ªôt s·ªë t·ª´ 1 (d·ªÖ) ƒë·∫øn 3 (kh√≥)>
    }}
    """

    try:
        response = gemini_model.generate_content(prompt)
        ai_json_data = json.loads(response.text)
        final_response = {
            "questionId": random.randint(1000, 9999),
            "questionText": ai_json_data.get("questionText"),
            "difficultyLevel": ai_json_data.get("difficultyLevel")
        }
        print(f"‚úÖ [Gemini] T·∫°o c√¢u h·ªèi th√†nh c√¥ng.")
        return jsonify(final_response), 200
    except Exception as e:
        print(f"üö® [Gemini] L·ªói: {str(e)}")
        return jsonify({"error": f"ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën v·ªõi Gemini: {str(e)}"}), 500


@app.route('/api/generate_report', methods=['POST'])
def generate_report_api():
    """
    API endpoint ƒë·ªÉ t·∫°o b√°o c√°o ƒë√°nh gi√°, s·ª≠ d·ª•ng Perplexity Pro (Reasoning).
    """
    if not perplexity_client:
        return jsonify({"error": "D·ªãch v·ª• Perplexity ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh ƒë√∫ng."}), 503
        
    try:
        data = request.get_json()
    except Exception:
        return jsonify({"error": "Request body kh√¥ng ph·∫£i l√† JSON h·ª£p l·ªá."}), 400

    question_text = data.get("questionText", "Kh√¥ng c√≥ c√¢u h·ªèi")
    answer_text = data.get("answerText", "")

    print(f"üß† [Perplexity] B·∫Øt ƒë·∫ßu t·∫°o b√°o c√°o ph√¢n t√≠ch...")

    # V·ªõi Perplexity, ch√∫ng ta truy·ªÅn message d∆∞·ªõi d·∫°ng m·ªôt danh s√°ch c√°c "role"
    messages = [
        {
            "role": "system",
            "content": (
                "B·∫°n l√† m·ªôt qu·∫£n l√Ω nh√¢n s·ª± v√† chuy√™n gia k·ªπ thu·∫≠t c·ª±c k·ª≥ kinh nghi·ªám. "
                "Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n t√≠ch c√¢u tr·∫£ l·ªùi c·ªßa ·ª©ng vi√™n v√† tr·∫£ v·ªÅ m·ªôt ƒë·ªëi t∆∞·ª£ng JSON duy nh·∫•t, "
                "kh√¥ng c√≥ b·∫•t k·ª≥ gi·∫£i th√≠ch hay markdown n√†o kh√°c."
            ),
        },
        {
            "role": "user",
            "content": f"""
            H√£y ph√¢n t√≠ch v√† ƒë√°nh gi√° c√¢u tr·∫£ l·ªùi ph·ªèng v·∫•n c·ªßa ·ª©ng vi√™n m·ªôt c√°ch kh√°ch quan.

            B·ªëi c·∫£nh ph·ªèng v·∫•n:
            - C√¢u h·ªèi: "{question_text}"
            - C√¢u tr·∫£ l·ªùi c·ªßa ·ª©ng vi√™n: "{answer_text}"

            H√£y tr·∫£ v·ªÅ m·ªôt ƒë·ªëi t∆∞·ª£ng JSON c√≥ c·∫•u tr√∫c ch√≠nh x√°c nh∆∞ sau, h√£y ƒëi·ªÅn n·ªôi dung ƒë√°nh gi√° c·ªßa b·∫°n v√†o c√°c tr∆∞·ªùng:
            {{
                "overallAssessment": "ƒê√°nh gi√° t·ªïng quan v·ªÅ ph·∫ßn tr·∫£ l·ªùi",
                "facialExpression": "D·ª±a tr√™n vƒÉn b·∫£n, suy ƒëo√°n v·ªÅ s·ª± t·ª± tin, bi·ªÉu c·∫£m",
                "speakingSpeedClarity": "D·ª±a tr√™n vƒÉn phong, nh·∫≠n x√©t v·ªÅ ƒë·ªô r√µ r√†ng, m·∫°ch l·∫°c",
                "expertiseExperience": "ƒê√°nh gi√° m·ª©c ƒë·ªô chuy√™n m√¥n v√† kinh nghi·ªám",
                "responseDurationPerQuestion": "∆Ø·ªõc l∆∞·ª£ng th·ªùi gian tr·∫£ l·ªùi ph√π h·ª£p, v√≠ d·ª•: 'Kho·∫£ng 45s'",
                "answerContentAnalysis": "Ph√¢n t√≠ch s√¢u v·ªÅ n·ªôi dung c√¢u tr·∫£ l·ªùi",
                "comparisonWithOtherCandidates": "So s√°nh v·ªõi m·∫∑t b·∫±ng chung",
                "problemSolvingSkills": "ƒê√°nh gi√° k·ªπ nƒÉng gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ",
                "status": "Completed"
            }}
            """,
        },
    ]

    try:
        # G·ªçi API c·ªßa Perplexity
        response = perplexity_client.chat.completions.create(
            model="llama-3-sonar-large-32k-chat", # M·ªôt model m·∫°nh m·∫Ω c·ªßa Perplexity
            messages=messages,
        )
        
        # L·∫•y n·ªôi dung text t·ª´ response v√† parse th√†nh JSON
        ai_response_text = response.choices[0].message.content
        ai_report = json.loads(ai_response_text)

        print("‚úÖ [Perplexity] T·∫°o b√°o c√°o th√†nh c√¥ng.")
        return jsonify(ai_report), 200

    except Exception as e:
        print(f"üö® [Perplexity] L·ªói: {str(e)}")
        # In th√™m response th√¥ n·∫øu c√≥ l·ªói ƒë·ªÉ d·ªÖ debug
        raw_response = getattr(e, 'response', None)
        if raw_response:
            print(f"Raw Perplexity Response: {raw_response.text}")
        return jsonify({"error": f"ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën v·ªõi Perplexity: {str(e)}"}), 500


# --- CH·∫†Y ·ª®NG D·ª§NG ---

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5001, debug=True)